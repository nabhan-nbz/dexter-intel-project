{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb8a76-7740-4766-b9d6-bcf76d7f1d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user datasets transformers scikit-learn intel-extension-for-transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b305d64-8d37-4e18-845e-6432ad7d912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb3411-4487-4063-9cd3-15a6c88530d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install intel-extension-for-transformers --target=intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/docs/notebooks/project\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c54d635-0296-438a-9ec5-95b1f43a4058",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yacs --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45f1997b-f12c-4d30-ab4a-b3d09a166531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simpy\n",
      "  Using cached simpy-4.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Using cached simpy-4.1.1-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: simpy\n",
      "Successfully installed simpy-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install simpy --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f665fc-e001-41c4-8c33-ae4b85bf1d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MentalAwarenessDataset(Dataset):\n",
    "    def __init__(self, questions, answers, tokenizer):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        answer = self.answers[idx]\n",
    "        inputs = self.tokenizer(question, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
    "        labels = self.tokenizer(answer, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).input_ids\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100  # Set padding tokens to -100 for CrossEntropyLoss\n",
    "        return {\n",
    "            \"input_ids\": inputs.input_ids.flatten(),\n",
    "            \"attention_mask\": inputs.attention_mask.flatten(),\n",
    "            \"labels\": labels.flatten(),\n",
    "        }\n",
    "\n",
    "# Load the dataset\n",
    "with open('output.json', 'r') as f:\n",
    "    mental_awareness_data = json.load(f)\n",
    "\n",
    "questions = [item['question'] for item in mental_awareness_data]\n",
    "answers = [item['answer'] for item in mental_awareness_data]\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"microsoft/DialoGPT-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Add special tokens if needed\n",
    "special_tokens_dict = {'pad_token': '[PAD]'}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Split the data into training and evaluation sets\n",
    "train_questions, eval_questions, train_answers, eval_answers = train_test_split(questions, answers, test_size=0.1)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MentalAwarenessDataset(train_questions, train_answers, tokenizer)\n",
    "eval_dataset = MentalAwarenessDataset(eval_questions, eval_answers, tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    learning_rate=3e-5,\n",
    "    warmup_steps=20,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",  # Save model every few steps\n",
    "    save_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"loss\"\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained('./fine_tuned2')\n",
    "tokenizer.save_pretrained('./fine_tuned2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db565285-3a7e-42df-8607-380765fc1340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm Dexter, your mental health awareness chatbot. How can I help you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: Hi! Dexter is here to assist you with any mental health concerns. How can I help today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is depression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: : Depression is a mood disorder that causes persistent feelings of sadness, loss of interest in activities once enjoyed, and a range of physical and emotional symptoms that can interfere with daily life.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is narcotics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: Narcotics, also known as opioids, are drugs that relieve pain and can produce euphoria. They include prescription medications like morphine and oxycodone, as well as illegal drugs like heroin. Narcotics can be highly addictive and have serious health risks.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  my friend is having suicide thoughts can you help him\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: Promote mental health awareness, reduce stigma surrounding mental illness, advocate for accessible mental health services, and educate others about suicide prevention.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDexter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Start the chat\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[43mchat_with_dexter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 41\u001b[0m, in \u001b[0;36mchat_with_dexter\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m chat_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbye\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDexter: Goodbye! Take care.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('./fine_tuned2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./fine_tuned2')\n",
    "\n",
    "\n",
    "with open('output.json', 'r') as f:\n",
    "    mental_awareness_data = json.load(f)\n",
    "\n",
    "questions = [item['question'] for item in mental_awareness_data]\n",
    "answers = [item['answer'] for item in mental_awareness_data]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(questions)\n",
    "\n",
    "def retrieve_response(query):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    question_vecs = vectorizer.transform(questions)\n",
    "    similarities = cosine_similarity(query_vec, question_vecs).flatten()\n",
    "\n",
    "    max_similarity = similarities.max()\n",
    "    if max_similarity > 0.2:  # Threshold for a good match\n",
    "        best_match_idx = similarities.argmax()\n",
    "        return answers[best_match_idx]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def generate_response(prompt, model, tokenizer):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs.input_ids, max_length=100, num_return_sequences=1, do_sample=True, top_k=50, top_p=0.95)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def chat_with_dexter():\n",
    "    print(\"Hi, I'm Dexter, your mental health awareness chatbot. How can I help you today?\")\n",
    "    chat_history = \"\"\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"Dexter: Goodbye! Take care.\")\n",
    "            break\n",
    "        \n",
    "    \n",
    "        chat_history += f\"User: {user_input}\\n\"\n",
    "        \n",
    "        \n",
    "        response = retrieve_response(user_input)\n",
    "        \n",
    "        if response:\n",
    "            chat_history += f\"Dexter: {response}\\n\"\n",
    "            print(f\"Dexter: {response}\")\n",
    "        else:\n",
    "            \n",
    "            try:\n",
    "                prompt = chat_history + f\"User: {user_input}\\nDexter: \"\n",
    "                generated_response = generate_response(prompt, model, tokenizer)\n",
    "                chat_history += f\"Dexter: {generated_response}\\n\"\n",
    "                print(f\"Dexter: {generated_response}\")\n",
    "            except Exception as e:\n",
    "                error_message = f\"Sorry, I couldn't process that. Please try again. (Error: {str(e)})\"\n",
    "                chat_history += f\"Dexter: {error_message}\\n\"\n",
    "                print(f\"Dexter: {error_message}\")\n",
    "\n",
    "# Start the chat\n",
    "chat_with_dexter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861c5d6-fb1c-49d5-9487-f7335b58f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained('./fine_tuned2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./fine_tuned2')\n",
    "\n",
    "# Load your mental awareness dataset\n",
    "with open('output.json', 'r') as f:\n",
    "    mental_awareness_data = json.load(f)\n",
    "\n",
    "questions = [item['question'] for item in mental_awareness_data]\n",
    "answers = [item['answer'] for item in mental_awareness_data]\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(questions)\n",
    "\n",
    "def retrieve_response(query):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    question_vecs = vectorizer.transform(questions)\n",
    "    similarities = cosine_similarity(query_vec, question_vecs).flatten()\n",
    "    \n",
    "    # Debugging information\n",
    "    print(\"Query:\", query)\n",
    "    print(\"Similarities:\", similarities)\n",
    "\n",
    "    max_similarity = similarities.max()\n",
    "    if max_similarity > 0.3:  # Lowered threshold for a good match\n",
    "        best_match_idx = similarities.argmax()\n",
    "        print(\"Best match index:\", best_match_idx)\n",
    "        return answers[best_match_idx]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def generate_response(prompt, model, tokenizer):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs.input_ids, max_length=100, num_return_sequences=1, do_sample=True, top_k=50, top_p=0.95)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def chat_with_dexter():\n",
    "    print(\"Hi, I'm Dexter, your mental health awareness chatbot. How can I help you today?\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"Dexter: Goodbye! Take care.\")\n",
    "            break\n",
    "        \n",
    "        # Try to retrieve a response from the dataset\n",
    "        response = retrieve_response(user_input)\n",
    "        \n",
    "        if response:\n",
    "            print(f\"Dexter: {response}\")\n",
    "        else:\n",
    "            # Generate a response if no good match is found\n",
    "            try:\n",
    "                generated_response = generate_response(user_input, model, tokenizer)\n",
    "                print(f\"Dexter: {generated_response}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Dexter: Sorry, I couldn't process that. Please try again. (Error: {str(e)})\")\n",
    "\n",
    "# Start the chat\n",
    "chat_with_dexter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3b70d32-b3f7-4932-8219-9638c74d3168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "  <meta charset=\"UTF-8\" />\n",
       "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
       "  <style>\n",
       "    body {\n",
       "      background-color: #f0f0f0;\n",
       "      font-family: \"Bona Nova SC\", sans-serif;\n",
       "      color: #333;\n",
       "      margin: 0;\n",
       "      padding: 0;\n",
       "    }\n",
       "    .container {\n",
       "      width: 80%;\n",
       "      margin: 0 auto;\n",
       "      padding: 20px;\n",
       "      background-color: #fff;\n",
       "      border: 1px solid #ccc;\n",
       "      border-radius: 5px;\n",
       "      box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
       "      display: flex;\n",
       "      flex-direction: column;\n",
       "      align-items: center;\n",
       "      position: relative;\n",
       "    }\n",
       "    .top-left-buttons {\n",
       "      margin-bottom: 20px;\n",
       "      align-self: flex-start;\n",
       "      position: relative;\n",
       "    }\n",
       "    .button {\n",
       "      display: inline-block;\n",
       "      padding: 10px 20px;\n",
       "      background-color: #6d839b;\n",
       "      color: #fff;\n",
       "      text-decoration: none;\n",
       "      border-radius: 5px;\n",
       "      margin-right: 10px;\n",
       "      transition: background-color 0.3s ease;\n",
       "    }\n",
       "    .button:hover {\n",
       "      background-color: #757f8a;\n",
       "    }\n",
       "    .button[type2] {\n",
       "      background-color: black;\n",
       "      margin-right: 20px;\n",
       "    }\n",
       "    .content {\n",
       "      display: flex;\n",
       "      justify-content: center;\n",
       "      align-items: center;\n",
       "      width: 100%;\n",
       "      flex: 1;\n",
       "    }\n",
       "    .left-section {\n",
       "      text-align: center;\n",
       "      flex: 1;\n",
       "    }\n",
       "    .right-section {\n",
       "      background-color: #f5f5f5;\n",
       "      padding: 20px;\n",
       "      border-radius: 5px;\n",
       "      display: flex;\n",
       "      flex-direction: column;\n",
       "      align-items: flex-end;\n",
       "    }\n",
       "    .bona-nova-sc-regular {\n",
       "      font-weight: 700;\n",
       "      font-size: 40px;\n",
       "      color: #333;\n",
       "      margin-bottom: 20px;\n",
       "      text-align: center;\n",
       "    }\n",
       "    .bona-nova-sc-bold {\n",
       "      font-weight: 700;\n",
       "      color: #007bff;\n",
       "      text-align: center;\n",
       "    }\n",
       "    .bona-nova-sc-regular-italic {\n",
       "      font-style: italic;\n",
       "      font-size: 18px;\n",
       "      color: #555;\n",
       "      text-align: center;\n",
       "    }\n",
       "    .image-container {\n",
       "      margin-top: 20px;\n",
       "      display: flex;\n",
       "      justify-content: flex-end;\n",
       "    }\n",
       "    .image-container img {\n",
       "      max-width: 100%;\n",
       "      height: auto;\n",
       "      border-radius: 5px;\n",
       "      max-height: 400px;\n",
       "    }\n",
       "    .about-message {\n",
       "      display: none;\n",
       "      position: absolute;\n",
       "      top: 0;\n",
       "      left: calc(100% + 10px);\n",
       "      padding: 20px;\n",
       "      background-color: #e9ecef;\n",
       "      border-radius: 5px;\n",
       "      text-align: center;\n",
       "      z-index: 1000;\n",
       "      width: 300px;\n",
       "    }\n",
       "  </style>\n",
       "  <title>Home</title>\n",
       "</head>\n",
       "<body>\n",
       "  <div class=\"container\">\n",
       "    <div class=\"top-left-buttons\">\n",
       "      <a href=\"#\" class=\"button type2\" onclick=\"toggleAboutMessage()\">About</a>\n",
       "      <div class=\"about-message\" id=\"about-message\">\n",
       "        HOLA!, My Name Is Dexter And Glad To Meet You. I Was Created By\n",
       "        Nabhan, Anand, Aldrin And Midhun Using The Resources Provided By\n",
       "        INTEL, Wishing I Was Of Help ......\n",
       "      </div>\n",
       "    </div>\n",
       "    <div class=\"content\">\n",
       "      <div class=\"left-section\">\n",
       "        <div>\n",
       "          <h1 class=\"bona-nova-sc-regular\">Welcome to</h1>\n",
       "          <h1 class=\"bona-nova-sc-regular\">\n",
       "            <span class=\"bona-nova-sc-bold\">Dexter</span>\n",
       "          </h1>\n",
       "          <h3 class=\"bona-nova-sc-regular-italic\">\n",
       "            Your personal mental health assistant\n",
       "          </h3>\n",
       "        </div>\n",
       "      </div>\n",
       "      <div class=\"right-section\">\n",
       "        <div class=\"image-container\">\n",
       "          <img src=\"look 3.0.jpg\" alt=\"Chatbot Image\" />\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "  </div>\n",
       "  <script>\n",
       "    function toggleAboutMessage() {\n",
       "      const aboutMessage = document.getElementById(\"about-message\");\n",
       "      if (aboutMessage.style.display === \"block\") {\n",
       "        aboutMessage.style.display = \"none\";\n",
       "      } else {\n",
       "        aboutMessage.style.display = \"block\";\n",
       "      }\n",
       "    }\n",
       "  </script>\n",
       "</body>\n",
       "</html>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm Dexter, your mental health awareness chatbot. How can I help you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: Hello! Dexter is here to support you. How are you feeling today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  i am feeling sad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: Im sorry to hear that. Dexter is here to support you. How can I help you through this?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  can you tell me what are the symptoms of depression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: Symptoms of depression include persistent sadness, loss of interest in activities, changes in appetite, and sleep disturbances. Individuals may also experience fatigue, feelings of worthlessness, and difficulty concentrating. Severe cases may lead to thoughts of selfharm or suicide.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  also how can i build resilience to stress\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: Building resilience involves developing strong social connections, maintaining a positive outlook, practicing selfcare, setting realistic goals, and adapting to change.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  how can i stay motivated to keep a new habit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: Keeping the end goal in mind, tracking progress, and rewarding yourself for small achievements can boost motivation. Dexter advises finding what personally motivates you and sticking to it.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  how do i choose which habit to start with\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: Start with a habit that aligns with your values and goals. Dexter recommends selecting a habit that is realistic and has a meaningful impact on your life.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  can you tell me what are the symptoms of paranoia\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: Symptoms of paranoia include constant suspicion, mistrust of others' intentions, feeling persecuted or threatened, hypervigilance, and difficulty relaxing or trusting even close friends or family.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is narcotics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: Narcotics, also known as opioids, are drugs that relieve pain and can produce euphoria. They include prescription medications like morphine and oxycodone, as well as illegal drugs like heroin. Narcotics can be highly addictive and have serious health risks.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what are the symptoms of narcotic withdrawal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: Symptoms of narcotic withdrawal include anxiety, muscle aches, sweating, nausea, and vomiting. Severe withdrawal can also cause agitation, insomnia, and high blood pressure. Medical supervision is often recommended during withdrawal to manage symptoms.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is national institute of mental health sciences\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: The National Institute of Mental Health Sciences (NIMHS) is a premier institution dedicated to mental health research. It focuses on understanding mental disorders and developing effective treatments. NIMHS also provides educational resources to enhance public mental health.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexter: Goodbye! Take care.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('./fine_tuned2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./fine_tuned2')\n",
    "\n",
    "\n",
    "with open('output.json', 'r') as f:\n",
    "    mental_awareness_data = json.load(f)\n",
    "\n",
    "questions = [item['question'] for item in mental_awareness_data]\n",
    "answers = [item['answer'] for item in mental_awareness_data]\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(questions)\n",
    "\n",
    "def retrieve_response(query):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    question_vecs = vectorizer.transform(questions)\n",
    "    similarities = cosine_similarity(query_vec, question_vecs).flatten()\n",
    "\n",
    "    max_similarity = similarities.max()\n",
    "    if max_similarity > 0.2:  # Threshold for a good match\n",
    "        best_match_idx = similarities.argmax()\n",
    "        return answers[best_match_idx]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def generate_response(prompt, model, tokenizer):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs.input_ids, max_length=100, num_return_sequences=1, do_sample=True, top_k=50, top_p=0.95)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "chat_history = \"\"\n",
    "\n",
    "def chat_with_dexter():\n",
    "    global chat_history\n",
    "    print( \"Hi, I'm Dexter, your mental health awareness chatbot. How can I help you today?\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"Dexter: Goodbye! Take care.\")\n",
    "            break\n",
    "        \n",
    "        chat_history += f\"User: {user_input}\\n\"\n",
    "        \n",
    "        response = retrieve_response(user_input)\n",
    "        \n",
    "        if response:\n",
    "            chat_history += f\"Dexter: {response}\\n\"\n",
    "            print(f\"Dexter: {response}\")\n",
    "        else:\n",
    "            try:\n",
    "                prompt = chat_history + f\"User: {user_input}\\nDexter: \"\n",
    "                generated_response = generate_response(prompt, model, tokenizer)\n",
    "                chat_history += f\"Dexter: {generated_response}\\n\"\n",
    "                print(f\"Dexter: {generated_response}\")\n",
    "            except Exception as e:\n",
    "                error_message = f\"Sorry, I couldn't process that. Please try again. (Error: {str(e)})\"\n",
    "                chat_history += f\"Dexter: {error_message}\\n\"\n",
    "                print(f\"Dexter: {error_message}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    display(HTML(filename='index.html'))\n",
    "    \n",
    " \n",
    "    chat_with_dexter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a3bbb-b671-4a5e-baad-7d4d5b753686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
